{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Revisando um pouco o curso do Datacamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'target', 'target_names', 'images', 'DESCR'])\n",
      "Optical Recognition of Handwritten Digits Data Set\n",
      "===================================================\n",
      "\n",
      "Notes\n",
      "-----\n",
      "Data Set Characteristics:\n",
      "    :Number of Instances: 5620\n",
      "    :Number of Attributes: 64\n",
      "    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\n",
      "    :Missing Attribute Values: None\n",
      "    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\n",
      "    :Date: July; 1998\n",
      "\n",
      "This is a copy of the test set of the UCI ML hand-written digits datasets\n",
      "http://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\n",
      "\n",
      "The data set contains images of hand-written digits: 10 classes where\n",
      "each class refers to a digit.\n",
      "\n",
      "Preprocessing programs made available by NIST were used to extract\n",
      "normalized bitmaps of handwritten digits from a preprinted form. From a\n",
      "total of 43 people, 30 contributed to the training set and different 13\n",
      "to the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\n",
      "4x4 and the number of on pixels are counted in each block. This generates\n",
      "an input matrix of 8x8 where each element is an integer in the range\n",
      "0..16. This reduces dimensionality and gives invariance to small\n",
      "distortions.\n",
      "\n",
      "For info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\n",
      "T. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\n",
      "L. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\n",
      "1994.\n",
      "\n",
      "References\n",
      "----------\n",
      "  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\n",
      "    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\n",
      "    Graduate Studies in Science and Engineering, Bogazici University.\n",
      "  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\n",
      "  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\n",
      "    Linear dimensionalityreduction using relevance weighted LDA. School of\n",
      "    Electrical and Electronic Engineering Nanyang Technological University.\n",
      "    2005.\n",
      "  - Claudio Gentile. A New Approximate Maximal Margin Classification\n",
      "    Algorithm. NIPS. 2000.\n",
      "\n",
      "(1797, 8, 8)\n",
      "(1797, 64)\n"
     ]
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from scipy.spatial import distance as dst\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Load the digits dataset: digits\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "# Print the keys and DESCR of the dataset\n",
    "print(digits.keys())\n",
    "print(digits['DESCR'])\n",
    "\n",
    "# Print the shape of the images and data keys\n",
    "print(digits.images.shape)\n",
    "print(digits.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.,   0.,   9.,  12.,  12.,  12.,   6.,   0.],\n",
       "       [  0.,   1.,  14.,   6.,   4.,   4.,   2.,   0.],\n",
       "       [  0.,   4.,  15.,  12.,   9.,   1.,   0.,   0.],\n",
       "       [  0.,   4.,  15.,   8.,  11.,  11.,   0.,   0.],\n",
       "       [  0.,   0.,   1.,   0.,   0.,  14.,   4.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,  10.,   8.,   0.],\n",
       "       [  0.,   0.,  10.,   1.,   0.,   8.,   8.,   0.],\n",
       "       [  0.,   0.,   9.,  16.,  16.,  15.,   4.,   0.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.images[1010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f103c26a278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display digit 1010\n",
    "plt.imshow(digits.images[1010], cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score:  0.990257480863\n",
      "Test Score:  0.983333333333\n"
     ]
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create feature and target arrays\n",
    "X = digits.data\n",
    "y = digits.target\n",
    "\n",
    "# Split into training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size = 0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Create a k-NN classifier with 7 neighbors: knn\n",
    "knn = KNeighborsClassifier(n_neighbors=7)\n",
    "# Neighbors s~a\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Print the accuracy\n",
    "print(\"Train Score: \",knn.score(X_train, y_train))\n",
    "print(\"Test Score: \",knn.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nota:** O que o algoritmo faz é calcular quais vizinhos estão mais pertos, neste caso ele calcula os 7 vizinhos e verifica onde eles estão localizados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Revisando um pouco com um pouco mais de detalhe o `kNN`, pode-se dizer que é um algoritmo `não paramétrico` . Ou seja, ele não faz nenhuma suposição sobre a forma da função que estamos prever. No caso, estamos trabalhando com imagens e não há nenhuma hipótese inicial sobre a forma dos nossos dados. Isso impede erros de modelagem. Por exemplo, suponha que nosso dado tem uma forma altamente `não Gaussiana`, mas o modelo de aprendizagemque escolhemos assume que nossos dados tenham uma distribuição `Gaussiana`. Isso seria meio bizarro, certo?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Além disso, é um algortimo \"Instance-Based learning\". Isto é, nosso algoritmo não faz nenhuma ação explícita quando aprende um modelo. Ou seja, o algoritmo faz uma \"escolha\" de \"memorizar\" os dados de treino e fazer a computação das distâncias no caso de teste.\n",
    "\n",
    "Em outras palavras, o kNN é conhecido por ter um treino mínimo mas ter um teste pesado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dito isso, será que conseguimos _reproduzir_ o _kNN_ na unha?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1797"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54.147945482723536"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist = np.linalg.norm(X[5]-X[4])\n",
    "dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0\n",
       "0  0\n",
       "1  1\n",
       "2  2\n",
       "3  3\n",
       "4  4"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_y = pd.DataFrame(y)\n",
    "df_y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X_train, y_train):\n",
    "    #TODO\n",
    "    # do exactly nothing\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(360, 64)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X_train, y_train, x_test, k, distance_metric=dst.euclidean):\n",
    "    prediction = []\n",
    "    assert X_train.shape[0]==y_train.shape[0], 'Wrong dimesion of y'\n",
    "    for test in tqdm(x_test):\n",
    "        dist_list = []\n",
    "        for index in range(len(X_train)):\n",
    "            dist = distance_metric(test,X_train[index])\n",
    "            dist_value = [dist, y_train[index]]\n",
    "            dist_list.append(dist_value)\n",
    "        dist_arr = np.array(dist_list)\n",
    "        #print('before ord',dist_arr)\n",
    "        dist_arr.view('i8,i8').sort(order=['f0'], axis=0)\n",
    "        #print('after ord',dist_arr[:7])\n",
    "        result = Counter(dist_arr[:k,1]).most_common(1)[0][0]\n",
    "        #print(result)\n",
    "        prediction.append(result)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_bolo(X_train, y_train, x_test, k, distance_metric=dst.euclidean):\n",
    "    result = []\n",
    "    for test in tqdm(x_test):\n",
    "        distances = []\n",
    "        targets = []\n",
    "        for i in range(len(X_train)):\n",
    "            distance = distance_metric(test, X_train[i,:])\n",
    "            distances.append([distance,i])\n",
    "\n",
    "        distances = sorted(distances)\n",
    "        for i in range(k):\n",
    "            index = distances[i][1]\n",
    "            targets.append(y_train[index])\n",
    "\n",
    "        result.append(Counter(targets).most_common(1))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 360/360 [00:06<00:00, 52.84it/s]\n",
      "100%|██████████| 360/360 [00:06<00:00, 52.36it/s]\n",
      "100%|██████████| 360/360 [00:07<00:00, 48.87it/s]\n",
      "100%|██████████| 360/360 [00:08<00:00, 43.06it/s]\n",
      "100%|██████████| 360/360 [00:07<00:00, 50.05it/s]\n",
      "100%|██████████| 360/360 [00:09<00:00, 39.47it/s]\n",
      "100%|██████████| 360/360 [00:07<00:00, 49.12it/s]\n",
      "100%|██████████| 360/360 [00:07<00:00, 50.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.63 s ± 747 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "timeit predict(X_train, y_train, X_test, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 360/360 [00:06<00:00, 53.58it/s]\n",
      "100%|██████████| 360/360 [00:06<00:00, 53.20it/s]\n",
      "100%|██████████| 360/360 [00:06<00:00, 51.43it/s]\n",
      "100%|██████████| 360/360 [00:07<00:00, 51.42it/s]\n",
      "100%|██████████| 360/360 [00:07<00:00, 49.33it/s]\n",
      "100%|██████████| 360/360 [00:08<00:00, 41.86it/s]\n",
      "100%|██████████| 360/360 [00:08<00:00, 41.67it/s]\n",
      "100%|██████████| 360/360 [00:07<00:00, 48.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.53 s ± 716 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "timeit predict_bolo(X_train, y_train, X_test, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The accuracy of OUR classifier is 98.33333333333333\n"
     ]
    }
   ],
   "source": [
    "pred = predict(X_train, y_train, X_test, 7)\n",
    "accuracy = accuracy_score(y_test, pred) * 100\n",
    "print('\\nThe accuracy of OUR classifier is {}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 360/360 [08:55<00:00,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Can't have more neighbors than training samples!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def kNearestNeighbor(X_train, y_train, X_test, predictions, k):\n",
    "    # check if k larger than n\n",
    "    if k > len(X_train):\n",
    "        raise ValueError\n",
    "\n",
    "    # train on the input data\n",
    "    train(X_train, y_train)\n",
    "\n",
    "    # predict for each testing observation\n",
    "    for i in tqdm(range(len(X_test))):\n",
    "        predictions.append(predict(X_train, y_train, X_test[i, :], k))\n",
    "\n",
    "# making our predictions \n",
    "predictions = []\n",
    "try:\n",
    "    kNearestNeighbor(X_train, y_train, X_test, predictions, 7)\n",
    "    predictions = np.asarray(predictions)\n",
    "\n",
    "    # evaluating accuracy\n",
    "    accuracy = accuracy_score(y_test, predictions) * 100\n",
    "    print('\\nThe accuracy of OUR classifier is %d%%' % accuracy)\n",
    "\n",
    "except ValueError:\n",
    "    print('Can\\'t have more neighbors than training samples!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Duas coisas a se pensar: As métricas de distância e o porquê do k's"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Sobre o número de k's\n",
    "\n",
    "Quando o número de K é pequeno, nós estamos restringindo a região para uma região específica e forçando o nosso classificador a ser mais \"cego\" em comparação com a distribuição total. É normal a formação de chamadas \"ilhas\". Um valor pequeno do K pode promover um fit mais flexível, mais complexo. Em outras palavras, nosso modelo consegue aprender bem para o caso de treino, mas falha em generalizar para casos não vistos. Assim, com um K baixo nós temos um bias baixo, mais uma variância alta. Isso pode causar o problema de overfitting\n",
    "\n",
    "![](../data/imgs/knn2.png)\n",
    "\n",
    "Como foi visto no curso do DataCamp, sob o pretesto de classificação, o K-NN basicamente forma um 'majoroty voting' entre os K pontos mais similares de acordo com uma métrica de distância, dado um ponto não visto. Em outras palavras, se eu tenho um ponto novo e os 5 caras mais próximos deles são azuis e 3 são vermelhos, então ele é azul.\n",
    "\n",
    "Contudo, um valor alto de K faz com que as `decision boundary` dos nossos dados seja mais \"suave\" de forma que nosso modelo generalize melhor (aumentando o seu bias e reduzindo a variância), mas talvez a decision boundary fique tão \"simples\" que nosso modelo falhe para classificações dos dados de treino (underfitting).\n",
    "\n",
    "![](../data/imgs/knn3.png)\n",
    "\n",
    "![](../data/imgs/knn8.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Sobre as métricas de distância"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como estamos considerando essa questão de \"proximidade\", há várias formas de pensarmos como a distância entre dois pontos pode ser computada já que elas podem representar diferentes formas de mostrar a similaridade entre dois pontos.\n",
    "\n",
    "Dependendo do problema que estamos tratando, o uso de diferentes métricas de distância pode impactar até a performance do desempenho do modelo.\n",
    "\n",
    "A mais comum é a distância L1, ou a Euclideana que nada mais é do que a ditância em uma linha reta entre dois pontos:\n",
    "\n",
    "`scipy.spatial.distance.euclidean()`. Contudo, existem várias outras: a Hamming , que serve para diferenças categóricas; Manhattan..\n",
    "\n",
    "\n",
    "O ponto é que existem várias métricas de distâncias e várias opções dependendo do seu problema.\n",
    "Vocês podem ver alguns exemplos aqui:\n",
    "https://docs.scipy.org/doc/scipy/reference/spatial.distance.html#module-scipy.spatial.distance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation\n",
    "\n",
    "Vimos dois exemplos de parâmetros que não são aprendidos pelo modelo: o uso de uma métrica de distiancia específica entre várias opções e o número ideal de K's. Ambos os casos são exemplos de **hiperparâmetros**. Na prática, sabemos que o melhor K é aquele que corresponde à menor taxa de erro para os nossos dados de teste.\n",
    "\n",
    "Então uma forma da gente testar isso seria testar diferentes K's para os nossos casos de teste, certo? **Errado** !\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A ideia aqui é a gente usar o nosso caso de teste para simularmos dados que nunca foram vistos. Ora, se a gente treina em cima dos dados de teste, nós estamos viciando nossos dados (e o pior, estamos treinando **usando dados de teste**) e isso é um caso claro de **overfitting**\n",
    "![](../data/imgs/knn4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Usar os dados de teste é algo que só deve ser feito ao final do pipeline de treinamento, quando já escolhemos, inclusive os hiperparâmetros**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma alternativa e aposta mais inteligente é fazer uma divisão a mais nos nossos dados. Nós passamos a dividir nosso conjunto de dados em três: treino, **validação** e teste. Esse conjunto de **validação** será usado para a escolha de hiperparâmetros do nosso algoritmo. Há diversas abordagens para atacar esse problema e uma das mais famosas é o _k-fold cross validation_.\n",
    "\n",
    "![](../data/imgs/knn5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como a imagem apresentada, o k-fold cross validation divide o dataset de treinamento em k grupos ou \"folds\" de aproximadamente mesmo tamanho. O primeiro grupo  é tratado como dataset de validação e os outros k-1 grupos são usados para treinar. Computa-se o erro e repete-se o processo K vezes, modificando o grupo que é tratado como dataset de validação. Esse processo resulta em k resultados, cuja média é o resultado final do desempenho do modelo.\n",
    "\n",
    "O scikit-learn já conta com esse tipo de método para fazer cross-validation, o `cross_val_score`. Nós especificamos o número de folds e nossa métrica é a acurácia já que estamos falando de classificação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating odd list of K for KNN\n",
    "myList = list(range(1,50))\n",
    "\n",
    "# subsetting just the odd ones\n",
    "neighbors = filter(lambda x: x % 2 != 0, myList)\n",
    "neighbors = list(neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbors_odd = list(range(1,50,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:05<00:00,  4.73it/s]\n"
     ]
    }
   ],
   "source": [
    "# empty list that will hold cv scores\n",
    "cv_scores = []\n",
    "\n",
    "# perform 10-fold cross validation\n",
    "for k in tqdm(neighbors):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    scores = cross_val_score(knn, X_train, y_train, cv=10, scoring='accuracy')\n",
    "    cv_scores.append(scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E agora nós podemos plotar o erro para cada caso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal number of neighbors is 3\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f10044e3080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# changing to misclassification error\n",
    "MSE = [1 - x for x in cv_scores]\n",
    "\n",
    "# determining best k\n",
    "optimal_k = neighbors[MSE.index(min(MSE))]\n",
    "print (\"The optimal number of neighbors is {}\".format(optimal_k))\n",
    "\n",
    "# plot misclassification error vs k\n",
    "plt.plot(neighbors, MSE)\n",
    "plt.xlabel('Number of Neighbors K')\n",
    "plt.ylabel('Misclassification Error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contudo, também tem outra estratégia muito melhor de fazermos a seleção dos hiperparâmetros ideias: o `grid search cv`, que basicamente além de fazer o cross validation, faz todas as combinações de hiperparâmetros desejada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Set the parameters by cross-validation\n",
    "tuned_parameters = [{'metric': ['euclidean', 'hamming'], 'n_neighbors': [1,2,3,4,5,6,7,8,9]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'metric': 'euclidean', 'n_neighbors': 1}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.990 (+/-0.019) for {'metric': 'euclidean', 'n_neighbors': 1}\n",
      "0.985 (+/-0.018) for {'metric': 'euclidean', 'n_neighbors': 2}\n",
      "0.990 (+/-0.018) for {'metric': 'euclidean', 'n_neighbors': 3}\n",
      "0.986 (+/-0.022) for {'metric': 'euclidean', 'n_neighbors': 4}\n",
      "0.986 (+/-0.025) for {'metric': 'euclidean', 'n_neighbors': 5}\n",
      "0.987 (+/-0.021) for {'metric': 'euclidean', 'n_neighbors': 6}\n",
      "0.985 (+/-0.032) for {'metric': 'euclidean', 'n_neighbors': 7}\n",
      "0.984 (+/-0.031) for {'metric': 'euclidean', 'n_neighbors': 8}\n",
      "0.981 (+/-0.026) for {'metric': 'euclidean', 'n_neighbors': 9}\n",
      "0.857 (+/-0.051) for {'metric': 'hamming', 'n_neighbors': 1}\n",
      "0.809 (+/-0.044) for {'metric': 'hamming', 'n_neighbors': 2}\n",
      "0.857 (+/-0.035) for {'metric': 'hamming', 'n_neighbors': 3}\n",
      "0.849 (+/-0.039) for {'metric': 'hamming', 'n_neighbors': 4}\n",
      "0.857 (+/-0.046) for {'metric': 'hamming', 'n_neighbors': 5}\n",
      "0.842 (+/-0.057) for {'metric': 'hamming', 'n_neighbors': 6}\n",
      "0.857 (+/-0.048) for {'metric': 'hamming', 'n_neighbors': 7}\n",
      "0.848 (+/-0.048) for {'metric': 'hamming', 'n_neighbors': 8}\n",
      "0.854 (+/-0.047) for {'metric': 'hamming', 'n_neighbors': 9}\n",
      "CPU times: user 21.1 s, sys: 7.76 ms, total: 21.1 s\n",
      "Wall time: 21.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf = GridSearchCV(KNeighborsClassifier(), tuned_parameters, cv=10)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(clf.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
